{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T14:45:33.141198Z",
     "start_time": "2025-04-10T14:45:30.498041Z"
    }
   },
   "source": [
    "from model.modeling_llama import LlamaForCausalLM as ModifiedLlama\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from kvcache.iterative import IterativeReduceKVBiasCache as ModifiedCache\n",
    "from transformers import DynamicCache\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from IPython.display import DisplayHandle\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "DEVICE = 'mps'\n",
    "DTYPE = torch.float32\n",
    "FIRST_N = 1000\n",
    "SAMPLE_SIZE = 10"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:45:33.147449Z",
     "start_time": "2025-04-10T14:45:33.142128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the cache file name\n",
    "CACHE_FILENAME = f\"fineweb_sample{SAMPLE_SIZE}of{FIRST_N}.csv\"\n",
    "\n",
    "# Check if the cache file already exists\n",
    "if os.path.exists(CACHE_FILENAME):\n",
    "    print(f\"Cache file already exists: {CACHE_FILENAME}\")\n",
    "    df = pd.read_csv(CACHE_FILENAME)\n",
    "else:\n",
    "    # Load streaming dataset\n",
    "    dataset = load_dataset(\"HuggingFaceFW/fineweb-edu\", split=\"train\", name=\"sample-10BT\", streaming=True)\n",
    "    stream = iter(dataset)\n",
    "\n",
    "    # Take 1000 streamed samples\n",
    "    samples = [next(stream) for _ in range(1000)]\n",
    "\n",
    "    # Randomly select 10 of them\n",
    "    selected_samples = random.sample(samples, 10)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(selected_samples)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(CACHE_FILENAME, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved CSV with {len(df)} samples to: {CACHE_FILENAME}\")\n",
    "\n",
    "texts = df[\"text\"]"
   ],
   "id": "388ca5340cb569b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache file already exists: fineweb_sample10of1000.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:45:33.151543Z",
     "start_time": "2025-04-10T14:45:33.147933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stepwise_perplexity(model, tokenizer, texts, cache_impl, update_every=10, max_length=256):\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    total_texts = len(texts)\n",
    "\n",
    "    display_handle = DisplayHandle()\n",
    "    display_handle.display(\"Starting perplexity evaluation...\")\n",
    "\n",
    "    for text_idx, text in enumerate(texts):\n",
    "        enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "        input_ids = enc[\"input_ids\"].squeeze(0).to(model.device)\n",
    "        cache = cache_impl()\n",
    "        seq_len = input_ids.size(0)\n",
    "\n",
    "        for i in range(1, seq_len):\n",
    "            input_slice = input_ids[i - 1 : i].unsqueeze(0)  # [1, 1]\n",
    "            label_token = input_ids[i].unsqueeze(0)          # [1]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(\n",
    "                    input_ids=input_slice,\n",
    "                    use_cache=True,\n",
    "                    past_key_values=cache,\n",
    "                )\n",
    "                cache = output.past_key_values\n",
    "                logits = output.logits[:, -1, :]  # [1, vocab_size]\n",
    "                loss = loss_fn(logits, label_token)\n",
    "                total_loss += loss.item()\n",
    "                total_tokens += 1\n",
    "\n",
    "            # Only update output every N steps for smooth UX\n",
    "            if total_tokens % update_every == 0 or (i == seq_len - 1 and text_idx == total_texts - 1):\n",
    "                current_ppl = np.exp(total_loss / total_tokens)\n",
    "\n",
    "                status = (f\"Text {text_idx + 1}/{total_texts} | \"\n",
    "                          f\"Token {i + 1}/{seq_len} \"\n",
    "                          f\"Global Steps: {total_tokens} | \"\n",
    "                          f\"Cumulative PPL: {current_ppl:.2f}\")\n",
    "                display_handle.update(status)\n",
    "\n",
    "    if total_tokens == 0:\n",
    "        return float(\"inf\")\n",
    "\n",
    "    return np.exp(total_loss / total_tokens)\n"
   ],
   "id": "8b865fd89b4ffa7e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:45:34.246904Z",
     "start_time": "2025-04-10T14:45:33.152055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_mod = ModifiedLlama.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")\n",
    "model_mod.eval().to(DEVICE).to(DTYPE)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")"
   ],
   "id": "fc76ac36ca500039",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:46:29.734374Z",
     "start_time": "2025-04-10T14:45:34.248279Z"
    }
   },
   "cell_type": "code",
   "source": "stepwise_perplexity(model_mod, tokenizer, [texts[0]], cache_impl=lambda: ModifiedCache(max_variance_increase=0.0), max_length=100)",
   "id": "90cc669d88c0f621",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text 1/1 | Token 100/100 Global Steps: 99 | Cumulative PPL: 10.69'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(10.687536180991414)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:47:19.796215Z",
     "start_time": "2025-04-10T14:46:29.735399Z"
    }
   },
   "cell_type": "code",
   "source": "stepwise_perplexity(model_mod, tokenizer, [texts[0]], cache_impl=lambda: ModifiedCache(max_variance_increase=1.0), max_length=100)",
   "id": "c5ff3150aea2c31c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text 1/1 | Token 100/100 Global Steps: 99 | Cumulative PPL: 10.71'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(10.708571431762966)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:48:09.461849Z",
     "start_time": "2025-04-10T14:47:19.797420Z"
    }
   },
   "cell_type": "code",
   "source": "stepwise_perplexity(model_mod, tokenizer, [texts[0]], cache_impl=lambda: ModifiedCache(max_variance_increase=5.0), max_length=100)",
   "id": "954a91e36ce740b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text 1/1 | Token 100/100 Global Steps: 99 | Cumulative PPL: 10.66'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(10.659794687357289)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:48:59.892406Z",
     "start_time": "2025-04-10T14:48:09.462476Z"
    }
   },
   "cell_type": "code",
   "source": "stepwise_perplexity(model_mod, tokenizer, [texts[0]], cache_impl=lambda: ModifiedCache(max_variance_increase=10.0), max_length=100)",
   "id": "93dd7d3f59aa497",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text 1/1 | Token 100/100 Global Steps: 99 | Cumulative PPL: 10.64'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(10.642912121315716)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:49:01.187017Z",
     "start_time": "2025-04-10T14:48:59.893542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_hf = AutoModelForCausalLM.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")\n",
    "model_hf.eval().to(DEVICE).to(DTYPE)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")"
   ],
   "id": "ce90a0a1123d0fce",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:49:05.118977Z",
     "start_time": "2025-04-10T14:49:01.187638Z"
    }
   },
   "cell_type": "code",
   "source": "stepwise_perplexity(model_hf, tokenizer, [texts[0]], cache_impl=lambda: None, max_length=100)",
   "id": "ea81927fecaccdb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text 1/1 | Token 100/100 Global Steps: 99 | Cumulative PPL: 10.69'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(10.687536180991414)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:49:05.121172Z",
     "start_time": "2025-04-10T14:49:05.119558Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dbc923eb81f6a806",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
