{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl"
   ],
   "id": "f7b68e9083d28981"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@triton.jit\n",
    "def kmeans_kernel(\n",
    "    X_ptr, centroids_ptr, new_centroids_ptr, cluster_counts_ptr, assignments_ptr, \n",
    "    B, H, L, C, D, \n",
    "    stride_x_b, stride_x_h, stride_x_l, stride_x_d,\n",
    "    stride_c_b, stride_c_h, stride_c_c, stride_c_d,\n",
    "    stride_nc_b, stride_nc_h, stride_nc_c, stride_nc_d,\n",
    "    stride_cc_b, stride_cc_h, stride_cc_c,\n",
    "    stride_a_b, stride_a_h, stride_a_l,\n",
    "    BLOCK_SIZE_L: tl.constexpr,\n",
    "    BLOCK_SIZE_C: tl.constexpr\n",
    "):\n",
    "    \"\"\"\n",
    "    Kernel to perform K-Means clustering:\n",
    "    1. Assign each point (B, H, L, D) to the closest centroid (B, H, C, D).\n",
    "    2. Compute new centroids using atomic updates.\n",
    "    \"\"\"\n",
    "    b_idx = tl.program_id(0)\n",
    "    h_idx = tl.program_id(1)\n",
    "    l_idx = tl.program_id(2) * BLOCK_SIZE_L + tl.arange(0, BLOCK_SIZE_L)\n",
    "\n",
    "    x_offset = b_idx * stride_x_b + h_idx * stride_x_h + l_idx * stride_x_l\n",
    "    c_offset = b_idx * stride_c_b + h_idx * stride_c_h\n",
    "\n",
    "    # Load input points\n",
    "    x = tl.load(X_ptr + x_offset[:, None] + tl.arange(0, D) * stride_x_d, mask=l_idx[:, None] < L, other=0.0)\n",
    "\n",
    "    # Track closest cluster\n",
    "    min_dist = tl.full([BLOCK_SIZE_L], float(\"inf\"), dtype=tl.float32)\n",
    "    best_cluster = tl.zeros([BLOCK_SIZE_L], dtype=tl.int32)\n",
    "\n",
    "    for c in range(0, C, BLOCK_SIZE_C):\n",
    "        c_idx = c + tl.arange(0, BLOCK_SIZE_C)\n",
    "\n",
    "        # Load centroids\n",
    "        centroids = tl.load(\n",
    "            centroids_ptr + c_offset + c_idx[:, None] * stride_c_c + tl.arange(0, D) * stride_c_d,\n",
    "            mask=c_idx[:, None] < C,\n",
    "            other=0.0\n",
    "        )\n",
    "\n",
    "        # Compute squared Euclidean distance\n",
    "        dists = tl.sum((x[:, None] - centroids) ** 2, axis=-1)\n",
    "\n",
    "        # Find the closest cluster\n",
    "        closer = dists < min_dist[:, None]\n",
    "        min_dist = tl.where(closer, dists, min_dist)\n",
    "        best_cluster = tl.where(closer, c_idx, best_cluster)\n",
    "\n",
    "    # Store assignments\n",
    "    tl.store(\n",
    "        assignments_ptr + b_idx * stride_a_b + h_idx * stride_a_h + l_idx * stride_a_l, best_cluster, \n",
    "        mask=l_idx < L\n",
    "    )\n",
    "\n",
    "    # Update centroids using atomic operations\n",
    "    for d in range(D):\n",
    "        value = tl.load(X_ptr + x_offset + d * stride_x_d, mask=l_idx < L)\n",
    "        for i in range(BLOCK_SIZE_L):\n",
    "            cluster = best_cluster[i]\n",
    "            tl.atomic_add(\n",
    "                new_centroids_ptr + b_idx * stride_nc_b + h_idx * stride_nc_h + cluster * stride_nc_c + d * stride_nc_d,\n",
    "                value[i]\n",
    "            )\n",
    "            tl.atomic_add(\n",
    "                cluster_counts_ptr + b_idx * stride_cc_b + h_idx * stride_cc_h + cluster * stride_cc_c,\n",
    "                1.0\n",
    "            )\n",
    "\n",
    "def kmeans_triton(X, num_clusters, num_iters=10):\n",
    "    \"\"\"\n",
    "    X: Tensor of shape (B, H, L, D)\n",
    "    num_clusters: Number of clusters C\n",
    "    Returns: centroids of shape (B, H, C, D)\n",
    "    \"\"\"\n",
    "    B, H, L, D = X.shape\n",
    "    C = num_clusters\n",
    "    device = X.device\n",
    "    \n",
    "    # Generate shuffled indices\n",
    "    shuffled_indices = torch.rand(B, H, L, device=device).argsort(dim=-1)  # (B, H, L)\n",
    "    \n",
    "    # Select the first C elements\n",
    "    indices = shuffled_indices[:, :, :C]  # (B, H, C)\n",
    "    \n",
    "    # Gather the centroids\n",
    "    centroids = torch.gather(X, 2, indices.unsqueeze(-1).expand(-1, -1, -1, D)).clone()\n",
    "\n",
    "    # Allocate storage for assignments, new centroids, and counts\n",
    "    assignments = torch.zeros((B, H, L), dtype=torch.int32, device=device)\n",
    "    new_centroids = torch.zeros((B, H, C, D), device=device)\n",
    "    cluster_counts = torch.zeros((B, H, C), device=device)\n",
    "\n",
    "    BLOCK_SIZE_L = min(64, L)  # Adapt to dataset size\n",
    "    grid = (B, H, triton.cdiv(L, BLOCK_SIZE_L))\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        # Reset new centroids and cluster counts\n",
    "        new_centroids.zero_()\n",
    "        cluster_counts.zero_()\n",
    "\n",
    "        # Assign points and compute new centroids\n",
    "        kmeans_kernel[grid](\n",
    "            X, centroids, new_centroids, cluster_counts, assignments,\n",
    "            B, H, L, C, D,\n",
    "            X.stride(0), X.stride(1), X.stride(2), X.stride(3),\n",
    "            centroids.stride(0), centroids.stride(1), centroids.stride(2), centroids.stride(3),\n",
    "            new_centroids.stride(0), new_centroids.stride(1), new_centroids.stride(2), new_centroids.stride(3),\n",
    "            cluster_counts.stride(0), cluster_counts.stride(1), cluster_counts.stride(2),\n",
    "            assignments.stride(0), assignments.stride(1), assignments.stride(2),\n",
    "            BLOCK_SIZE_L=64, BLOCK_SIZE_C=32\n",
    "        )\n",
    "        \n",
    "        # Update centroids\n",
    "        centroids = new_centroids / (cluster_counts + 1e-6)\n",
    "\n",
    "    return centroids"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.jit\n",
    "def kmeans_assign_kernel(\n",
    "    X_ptr, centroids_ptr, assignments_ptr,\n",
    "    B, H, L, C, D,\n",
    "    stride_x_b, stride_x_h, stride_x_l, stride_x_d,\n",
    "    stride_c_b, stride_c_h, stride_c_c, stride_c_d,\n",
    "    stride_a_b, stride_a_h, stride_a_l,\n",
    "    BLOCK_SIZE_L: tl.constexpr,\n",
    "    BLOCK_SIZE_C: tl.constexpr\n",
    "):\n",
    "    \"\"\"\n",
    "    Kernel to assign each point to the closest centroid.\n",
    "    \"\"\"\n",
    "    b_idx = tl.program_id(0)\n",
    "    h_idx = tl.program_id(1)\n",
    "    l_idx = tl.program_id(2) * BLOCK_SIZE_L + tl.arange(0, BLOCK_SIZE_L)\n",
    "\n",
    "    x_offset = b_idx * stride_x_b + h_idx * stride_x_h + l_idx * stride_x_l\n",
    "    c_offset = b_idx * stride_c_b + h_idx * stride_c_h\n",
    "\n",
    "    # Load input points\n",
    "    x = tl.load(X_ptr + x_offset[:, None] + tl.arange(0, D) * stride_x_d, mask=l_idx[:, None] < L, other=0.0)\n",
    "\n",
    "    # Track closest cluster\n",
    "    min_dist = tl.full([BLOCK_SIZE_L], 1e30, dtype=tl.float32)\n",
    "    best_cluster = tl.zeros([BLOCK_SIZE_L], dtype=tl.int32)\n",
    "\n",
    "    for c in range(0, C, BLOCK_SIZE_C):\n",
    "        c_idx = c + tl.arange(0, BLOCK_SIZE_C)\n",
    "\n",
    "        # Load centroids\n",
    "        centroids = tl.load(\n",
    "            centroids_ptr + c_offset + c_idx[:, None] * stride_c_c + tl.arange(0, D) * stride_c_d,\n",
    "            mask=c_idx[:, None] < C,\n",
    "            other=0.0\n",
    "        )\n",
    "\n",
    "        # Compute squared Euclidean distance\n",
    "        dists = tl.sum((x[:, None] - centroids) ** 2, axis=-1)\n",
    "\n",
    "        # Find the closest cluster\n",
    "        closer = dists < min_dist[:, None]\n",
    "        min_dist = tl.where(closer, dists, min_dist)\n",
    "        best_cluster = tl.where(closer, c_idx, best_cluster)\n",
    "\n",
    "    # Store assignments\n",
    "    tl.store(\n",
    "        assignments_ptr + b_idx * stride_a_b + h_idx * stride_a_h + l_idx * stride_a_l, best_cluster, \n",
    "        mask=l_idx < L\n",
    "    )\n",
    "\n",
    "@triton.jit\n",
    "def kmeans_update_kernel(\n",
    "    X_ptr, new_centroids_ptr, cluster_counts_ptr, assignments_ptr,\n",
    "    B, H, L, C, D,\n",
    "    stride_x_b, stride_x_h, stride_x_l, stride_x_d,\n",
    "    stride_nc_b, stride_nc_h, stride_nc_c, stride_nc_d,\n",
    "    stride_cc_b, stride_cc_h, stride_cc_c,\n",
    "    stride_a_b, stride_a_h, stride_a_l,\n",
    "    BLOCK_SIZE_L: tl.constexpr,\n",
    "    BLOCK_SIZE_C: tl.constexpr\n",
    "):\n",
    "    \"\"\"\n",
    "    Kernel to compute new centroids based on the assignments, handling multiple centroids at once.\n",
    "    \"\"\"\n",
    "    b_idx = tl.program_id(0)\n",
    "    h_idx = tl.program_id(1)\n",
    "    c_start = tl.program_id(2) * BLOCK_SIZE_C\n",
    "    c_idx = c_start + tl.arange(0, BLOCK_SIZE_C)\n",
    "\n",
    "    mask_c = c_idx < C  # Mask for valid centroids\n",
    "    sum_x = tl.zeros([BLOCK_SIZE_C, D], dtype=tl.float32)\n",
    "    count = tl.zeros([BLOCK_SIZE_C], dtype=tl.float32)\n",
    "\n",
    "    for l in range(0, L, BLOCK_SIZE_L):\n",
    "        l_idx = l + tl.arange(0, BLOCK_SIZE_L)\n",
    "        mask_l = l_idx < L\n",
    "\n",
    "        # Load assignments\n",
    "        cluster = tl.load(\n",
    "            assignments_ptr + b_idx * stride_a_b + h_idx * stride_a_h + l_idx * stride_a_l, \n",
    "            mask=mask_l, other=-1\n",
    "        )\n",
    "\n",
    "        # Load points\n",
    "        x = tl.load(\n",
    "            X_ptr + b_idx * stride_x_b + h_idx * stride_x_h + l_idx[:, None] * stride_x_l + tl.arange(0, D) * stride_x_d,\n",
    "            mask=mask_l[:, None], \n",
    "            other=0.0\n",
    "        )\n",
    "\n",
    "        # Compute cluster membership for all centroids in the current block\n",
    "        belongs_to_cluster = cluster[:, None] == c_idx[None, :]\n",
    "        sum_x += tl.sum(x[:, None, :] * belongs_to_cluster[:, :, None], axis=0)\n",
    "        count += tl.sum(belongs_to_cluster, axis=0)\n",
    "\n",
    "    # Store new centroids\n",
    "    tl.store(\n",
    "        new_centroids_ptr + b_idx * stride_nc_b + h_idx * stride_nc_h + c_idx[:, None] * stride_nc_c + tl.arange(0, D) * stride_nc_d,\n",
    "        sum_x, \n",
    "        mask=mask_c[:, None]\n",
    "    )\n",
    "    tl.store(\n",
    "        cluster_counts_ptr + b_idx * stride_cc_b + h_idx * stride_cc_h + c_idx * stride_cc_c,\n",
    "        count, \n",
    "        mask=mask_c\n",
    "    )\n",
    "\n",
    "def kmeans_triton(X, num_clusters, num_iters=10):\n",
    "    \"\"\"\n",
    "    X: Tensor of shape (B, H, L, D)\n",
    "    num_clusters: Number of clusters C\n",
    "    Returns: centroids of shape (B, H, C, D)\n",
    "    \"\"\"\n",
    "    B, H, L, D = X.shape\n",
    "    C = num_clusters\n",
    "    device = X.device\n",
    "    \n",
    "    X = X.contiguous()\n",
    "    \n",
    "    # Initialize centroids\n",
    "    shuffled_indices = torch.rand(B, H, L, device=device).argsort(dim=-1)\n",
    "    indices = shuffled_indices[:, :, :C]\n",
    "    centroids = torch.gather(X, 2, indices.unsqueeze(-1).expand(-1, -1, -1, D)).clone()\n",
    "\n",
    "    assignments = torch.zeros((B, H, L), dtype=torch.int32, device=device)\n",
    "    new_centroids = torch.zeros((B, H, C, D), device=device)\n",
    "    cluster_counts = torch.zeros((B, H, C), device=device)\n",
    "\n",
    "    BLOCK_SIZE_L = min(64, L)\n",
    "    grid_assign = (B, H, triton.cdiv(L, BLOCK_SIZE_L))\n",
    "    BLOCK_SIZE_C = min(32, C)  # Number of centroids processed in parallel\n",
    "    grid_update = (B, H, triton.cdiv(C, BLOCK_SIZE_C))\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        new_centroids.zero_()\n",
    "        cluster_counts.zero_()\n",
    "\n",
    "        # Assign points\n",
    "        kmeans_assign_kernel[grid_assign](\n",
    "            X, centroids, assignments,\n",
    "            B, H, L, C, D,\n",
    "            X.stride(0), X.stride(1), X.stride(2), X.stride(3),\n",
    "            centroids.stride(0), centroids.stride(1), centroids.stride(2), centroids.stride(3),\n",
    "            assignments.stride(0), assignments.stride(1), assignments.stride(2),\n",
    "            BLOCK_SIZE_L=64, BLOCK_SIZE_C=32\n",
    "        )\n",
    "        \n",
    "        # Update centroids\n",
    "        kmeans_update_kernel[grid_update](\n",
    "            X, new_centroids, cluster_counts, assignments,\n",
    "            B, H, L, C, D,\n",
    "            X.stride(0), X.stride(1), X.stride(2), X.stride(3),\n",
    "            new_centroids.stride(0), new_centroids.stride(1), new_centroids.stride(2), new_centroids.stride(3),\n",
    "            cluster_counts.stride(0), cluster_counts.stride(1), cluster_counts.stride(2),\n",
    "            assignments.stride(0), assignments.stride(1), assignments.stride(2),\n",
    "            BLOCK_SIZE_L=64, BLOCK_SIZE_C=32\n",
    "        )\n",
    "        \n",
    "        valid_clusters = cluster_counts > 0\n",
    "        centroids[valid_clusters] = new_centroids[valid_clusters] / cluster_counts[valid_clusters]\n",
    "        \n",
    "        empty_clusters = ~valid_clusters \n",
    "        if empty_clusters.any():\n",
    "            start = torch.randint(0, L - C, (1,), device=device).item()\n",
    "            reinit_indices = shuffled_indices[:, :, start:start + C]\n",
    "            new_centroids = torch.gather(X, 2, reinit_indices.unsqueeze(-1).expand(-1, -1, -1, D))\n",
    "            centroids[empty_clusters] = new_centroids[empty_clusters]\n",
    "    \n",
    "    return centroids, cluster_counts\n"
   ],
   "id": "def11ad5733ce8e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def kmeans_pytorch(X, num_clusters, num_iters=10):\n",
    "    \"\"\"\n",
    "    Pure PyTorch implementation of k-means clustering.\n",
    "    \n",
    "    X: Tensor of shape (B, H, L, D)\n",
    "    num_clusters: Number of clusters C\n",
    "    Returns: centroids of shape (B, H, C, D)\n",
    "    \"\"\"\n",
    "    B, H, L, D = X.shape\n",
    "    C = num_clusters\n",
    "    device = X.device\n",
    "    \n",
    "    X = X.contiguous()\n",
    "    \n",
    "    # Initialize centroids\n",
    "    shuffled_indices = torch.rand(B, H, L, device=device).argsort(dim=-1)\n",
    "    indices = shuffled_indices[:, :, :C]\n",
    "    centroids = torch.gather(X, 2, indices.unsqueeze(-1).expand(-1, -1, -1, D)).clone()\n",
    "    \n",
    "    new_centroids = torch.zeros_like(centroids)\n",
    "    cluster_counts = torch.zeros((B, H, C), dtype=torch.float32, device=device)\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "        # Compute distances: (B, H, L, C)\n",
    "        dists = torch.cdist(X.view(B * H, L, D), centroids.view(B * H, C, D)).view(B, H, L, C)\n",
    "        \n",
    "        # Assign each point to the closest centroid\n",
    "        assignments = dists.argmin(dim=-1)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        new_centroids.zero_()\n",
    "        cluster_counts.zero_()\n",
    "        \n",
    "        for c in range(C):\n",
    "            mask = assignments == c  # (B, H, L)\n",
    "            count = mask.sum(dim=-1, keepdim=True).float()  # (B, H, 1)\n",
    "            \n",
    "            # Sum selected points\n",
    "            sum_x = torch.where(mask.unsqueeze(-1), X, torch.zeros_like(X)).sum(dim=2)\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            valid_clusters = count.squeeze(-1) > 0\n",
    "            new_centroids[valid_clusters, c] = sum_x[valid_clusters] / count[valid_clusters]\n",
    "        \n",
    "        # Handle empty clusters by reinitializing\n",
    "        empty_clusters = cluster_counts == 0\n",
    "        if empty_clusters.any():\n",
    "            start = torch.randint(0, L - C, (1,), device=device)\n",
    "            reinit_indices = shuffled_indices[:, :, start:start + C]\n",
    "            new_centroids[empty_clusters] = torch.gather(X, 2, reinit_indices.unsqueeze(-1).expand(-1, -1, -1, D))[empty_clusters]\n",
    "        \n",
    "        centroids = new_centroids.clone()\n",
    "    \n",
    "    return centroids, cluster_counts"
   ],
   "id": "902e00eb79afa4f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
